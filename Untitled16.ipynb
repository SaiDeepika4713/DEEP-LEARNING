{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xJIrcup2SuY3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_gesture(test_video_path, gesture_representation_path):\n",
        "    gesture_representation = cv2.imread(gesture_representation_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if gesture_representation is None:\n",
        "        print(\"Error: Unable to load gesture representation.\")\n",
        "        return\n",
        "\n",
        "    cap = cv2.VideoCapture(test_video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Unable to open test video.\")\n",
        "        return\n",
        "\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Perform template matching\n",
        "        result = cv2.matchTemplate(gray_frame, gesture_representation, cv2.TM_CCOEFF_NORMED)\n",
        "\n",
        "        threshold = 0.8\n",
        "        loc = np.where(result >= threshold)\n",
        "        cv2.putText(frame, 'DETECTED', (width - 150, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_video_path = '/content/WhatsApp Video 2024-04-11 at 7.27.38 PM.mp4'\n",
        "    gesture_representation_path = '/content/thumbsup.jpg'\n",
        "    detect_gesture(test_video_path, gesture_representation_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Detection Locations:\", loc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "15kZ03pmUGSi",
        "outputId": "8bb4cef2-b675-4a86-a58c-9fde8eddd5d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'loc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-210059a0e0e4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Detection Locations:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'loc' is not defined"
          ]
        }
      ]
    }
  ]
}